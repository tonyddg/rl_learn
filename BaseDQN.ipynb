{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本 DQN\n",
    "> 参考自 <https://hrl.boyuai.com/chapter/2/dqn%E7%AE%97%E6%B3%95/>\n",
    "\n",
    "## 概述\n",
    "* 包含 Double DQN 与经验回放的 DQN\n",
    "* 模型实现代码 `./dqn/BaseDQN.py`\n",
    "* 测试环境 gymnasium CartPole-v0\n",
    "\n",
    "## 记录\n",
    "* v1.0\n",
    "    * 如果 loss 不断发散, 可能是出现严重的高估问题, 可通过检查经验队列中特定动作是否高频次出现\n",
    "    * 当环境结束时, td target 不需要再需要模型预测 (未来奖励一定是 0)\n",
    "* v1.1\n",
    "    * 修复: 向量化动作决策时, 所有 batch 公用了一个 epsilon 判断结果 (对运行没有影响)\n",
    "    * 修复: 模型训练时, 应使用 trasition 的 action 预测, 而不是 state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordEpisodeStatistics, RecordVideo\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dqn.BaseDQN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(name: str, comment: str, episode: int = 500, hparam: HyperParam | None = None, is_write: bool = True):\n",
    "    '''\n",
    "    * `name` 训练名称\n",
    "    * `comment` 训练注释\n",
    "    * `episode` 训练片段数\n",
    "    * `hparam` 超参数\n",
    "    * `is_write` 是否记录训练数据\n",
    "    '''\n",
    "    env = gym.make(\n",
    "        \"CartPole-v0\", \n",
    "        render_mode = \"rgb_array\"\n",
    "    )\n",
    "    if is_write:\n",
    "        env = RecordEpisodeStatistics(env, buffer_length = 1)\n",
    "        env = RecordVideo(\n",
    "            env, \n",
    "            video_folder = \"vedio_CartPole_with_BaseDQN\", \n",
    "            name_prefix = name,\n",
    "            episode_trigger = lambda x: (x + 1) % 100 == 0\n",
    "        )\n",
    "\n",
    "    if hparam == None:\n",
    "        hparam = HyperParam()\n",
    "    model = BaseDQN(hparam)\n",
    "\n",
    "    writer = None\n",
    "    if is_write:\n",
    "        writer = SummaryWriter(comment = name + \"_\" + comment)\n",
    "\n",
    "    for episode in tqdm(range(episode)):\n",
    "        state, info = env.reset()\n",
    "        done = False\n",
    "        total_loss = 0\n",
    "\n",
    "        while not done:\n",
    "            \n",
    "            # 完成一次状态转移\n",
    "            action = model.take_action_single(state)\n",
    "            next_state, reward, terminated, truncated, info = env.step(action[0])\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # 更新模型\n",
    "            transition = make_transition_from_numpy(state, action, next_state, reward, terminated)\n",
    "            loss = model.update(transition)\n",
    "            if loss != False:\n",
    "                total_loss += loss\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "        model.update_episode(episode)\n",
    "\n",
    "        # tensorboard 记录平均损失与累计回报\n",
    "        if writer != None:        \n",
    "            writer.add_scalar(\n",
    "                f\"{name}/avg_loss\",\n",
    "                total_loss / info[\"episode\"][\"l\"],\n",
    "                episode\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                f\"{name}/return\",\n",
    "                info[\"episode\"][\"r\"],\n",
    "                episode\n",
    "            )\n",
    "\n",
    "        # 记录动作倾向\n",
    "        if writer != None:  \n",
    "            if episode % 50 == 0:\n",
    "                action_sum = 0\n",
    "                for i in model.reply_queue.buffer:\n",
    "                    action_sum += i.action.item()\n",
    "\n",
    "                writer.add_scalar(\n",
    "                    f\"{name}/avg_action\",\n",
    "                    action_sum / model.reply_queue.size(),\n",
    "                    int(episode / 50)\n",
    "                )\n",
    "    env.close()\n",
    "    \n",
    "    if writer != None:\n",
    "        writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparam = HyperParam()\n",
    "train(\"cartpole-v0\", \"test\", 500, is_write = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行结果\n",
    "\n",
    "## v1.1\n",
    "![](./res/CartPole_v0_BaseDQN_v1_1.png)\n",
    "\n",
    "## todo\n",
    "* 优化代码, 计算 TD 目标时, 当 done 为 True 时不进行预测\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
